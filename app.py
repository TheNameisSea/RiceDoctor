#_____Imports_____#
# Timm
import sys
sys.path.append('../input/pytorch-image-models/pytorch-image-models-master')

# Settings
import warnings
import sklearn.exceptions
warnings.filterwarnings('ignore', category=DeprecationWarning)
warnings.filterwarnings('ignore', category=FutureWarning)
warnings.filterwarnings("ignore", category=sklearn.exceptions.UndefinedMetricWarning)

# General
from collections import defaultdict
import pandas as pd
import numpy as np
import os, shutil
import random
import gc
import cv2
from PIL import Image
import glob
import random
import json 
gc.enable()
pd.set_option('display.max_columns', None)

# Augmentations
import albumentations
from albumentations.pytorch.transforms import ToTensorV2

# Deep Learning
from torch.utils.data import Dataset, DataLoader
import torch
import torchvision
import timm
import torch.nn as nn
import torch.nn.functional as F
from model import NeuralNet
from nltk_utils import bag_of_words, tokenize

# UI
import streamlit as st
from streamlit_chat import message
from streamlit_extras.colored_header import colored_header
from streamlit_extras.add_vertical_space import add_vertical_space

# Seeds
RANDOM_SEED = 42

def seed_everything(seed=RANDOM_SEED):
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = True
    
seed_everything()

# Device
device = torch.device('cpu')

#_____Data_____#
# required datafile
data_dir = './input'        # image folder
models_dir = './models'     # model folder
test_df = pd.DataFrame(columns=['image_id', 'label'])

id2label = {0: 'Báº¡c lÃ¡',
            1: 'Äá»‘m sá»c lÃ¡',
            2: 'Báº¡c chuá»³ lÃ¡',
            3: 'ChÃ¡y lÃºa',
            4: 'Äá»‘m nÃ¢u',
            5: 'SÃ¢u Ä‘á»¥c thÃ¢n lÃºa',
            6: 'SÆ°Æ¡ng mai',
            7: 'Bá» gai',
            8: 'BÃ¬nh thÆ°á»ng',
            9: 'Vi-rÃºt Tungro',
            10: 'KhÃ´ng xÃ¡c Ä‘á»‹nh'}

with open('./chat/intents.json', 'r') as json_data:
    intents = json.load(json_data)

with open('./info.json', 'r') as diseases_info:
    info = json.load(diseases_info)

chat_file = "./chat/chatbot_data.pth"
chatbot_data = torch.load(chat_file)

# Params
params = {
    'model': 'efficientnet_b3',
    'pretrained': False,
    'inp_channels': 3,
    'im_size': 300,
    'device': device,
    'batch_size': 85,
    'num_workers' : 0,
    'out_features': 11,
    'dropout': 0.2,
    'num_fold': 10,
    'debug': False,
}

# Transform
def get_test_transforms(DIM = params['im_size']):
    return albumentations.Compose(
        [
          albumentations.Resize(DIM,DIM),
          albumentations.Normalize(
              mean=[0.485, 0.456, 0.406],
              std=[0.229, 0.224, 0.225],
          ),
          ToTensorV2(p=1.0)
        ]
    )

# Dataset and Dataloader
class PaddyDataset(Dataset):
    def __init__(self, images_filepaths, transform=None):
        self.images_filepaths = images_filepaths
        self.transform = transform

    def __len__(self):
        return len(self.images_filepaths)

    def __getitem__(self, idx):
        image_filepath = self.images_filepaths[idx]
        image = cv2.imread(image_filepath)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        if self.transform is not None:
            image = self.transform(image=image)['image']
        
        return image

#_____Deep Learning_____#
# PaddyNet
class PaddyNet(nn.Module):
    def __init__(self, model_name=params['model'], out_features=params['out_features'], inp_channels=params['inp_channels'],
                 pretrained=params['pretrained']):
        super().__init__()
        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=inp_channels)
        out_channels = self.model.conv_stem.out_channels
        kernel_size = self.model.conv_stem.kernel_size
        stride = self.model.conv_stem.stride
        padding = self.model.conv_stem.padding
        bias = self.model.conv_stem.bias
        self.model.conv_stem = nn.Conv2d(inp_channels, out_channels,
                                          kernel_size=kernel_size, stride=stride,
                                          padding=padding, bias=bias)
        n_features = self.model.classifier.in_features
        self.model.classifier = nn.Identity()
        self.dropout = nn.Dropout(params['dropout'])
        self.fc = nn.Linear(n_features, out_features)
    
    def forward(self, image):
        embeddings = self.model(image)
        x = self.dropout(embeddings)
        output = self.fc(x)
        return output
    
# Chatbot
all_words = chatbot_data['all_words']
tags = chatbot_data['tags']
model_state = chatbot_data["model_state"]

chat_model = NeuralNet(input_size=chatbot_data["input_size"], hidden_size=chatbot_data["hidden_size"], num_classes=chatbot_data["output_size"]).to(device)
chat_model.load_state_dict(model_state)
chat_model.eval()

# Utils
def get_text():
    input_text = st.text_input("You: ", "", key="input")
    return input_text

def generate_response(msg):
    response = "Xin lá»—i, tÃ´i khÃ´ng hiá»ƒu cÃ¢u há»i."

    sentence = tokenize(msg)
    X = bag_of_words(sentence, all_words)
    X = X.reshape(1, X.shape[0])
    X = torch.from_numpy(X).to(device)

    output = chat_model(X)
    _, predicted = torch.max(output, dim=1)

    tag = tags[predicted.item()]

    probs = torch.softmax(output, dim=1)
    prob = probs[0][predicted.item()]
    if prob.item() > 0.5:
        for intent in intents['intents']:
            if tag == intent["tag"]:
                response = random.choice(intent['responses'])
                return response
    
    return response

@st.cache_data
def load_image(image_file):
    img = Image.open(image_file)
    return img

# Page cfgs
st.set_page_config(page_title="Rice Disease Classification", page_icon="ğŸ”¬", layout="centered", initial_sidebar_state="expanded", menu_items=None) 

# Page Title
tab1, tab2 = st.tabs(["Cháº©n Ä‘oÃ¡n", "RdpChat"])

with tab1:
    st.write("""
    # BÃ¡c SÄ© LÃºa
    Cháº©n Ä‘oÃ¡n bá»‡nh lÃºa dá»±a trÃªn hÃ¬nh áº£nh 
    """)
    st.write('[LÆ°u Ã½:]')
    luu_y = [
        'Sáº£n pháº©m chá»‰ sá»­ dá»¥ng Ä‘Æ°á»£c cho lÃºa, xin vui lÃ²ng khÃ´ng nháº­p áº£nh cá»§a cÃ¡c váº­t khÃ¡c vÃ o app',
        'NhÃ  phÃ¡t triá»ƒn khÃ´ng Ä‘áº£m báº£o Ä‘á»™ chÃ­nh xÃ¡c cá»§a dá»± Ä‘oÃ¡n cho táº¥t cáº£ cÃ¡c dá»± Ä‘oÃ¡n dá»±a trÃªn áº£nh cá»§a cÃ¡c giá»‘ng cÃ¢y ngoÃ i lÃºa',
        'Chá»‰ cÃ³ tÃ¡c dá»¥ng vá»›i áº£nh chá»¥p tá»« Ä‘iá»‡n thoáº¡i (tá»‰ lá»‡ 4:3, Ä‘á»™ phÃ¢n giáº£i khuyáº¿n khÃ­ch: 1440x1080)'
    ]
    st.write(luu_y)
            
    st.sidebar.header('Táº£i áº£nh lÃªn Ä‘á»ƒ báº¯t Ä‘áº§u cháº©n Ä‘oÃ¡n')
    uploaded_files = st.sidebar.file_uploader("Táº£i áº£nh", accept_multiple_files=True)

    res_col, img_col = st.columns([4, 2])

    if uploaded_files is not None:
        try:
            if os.path.exists('./upload'):
                shutil.rmtree('./upload')
            os.mkdir('./upload')
            upload_path = "./upload"

            # os.chdir('./database')
            # for uploaded_file in uploaded_files:
            #     img = load_image(uploaded_file)
            #     with open(uploaded_file.name, "wb") as f:
            #         f.write(uploaded_file.getbuffer())
            # os.chdir('../')

            os.chdir(upload_path)
            for uploaded_file in uploaded_files:
                img = load_image(uploaded_file)
                with open(uploaded_file.name, "wb") as f:
                    f.write(uploaded_file.getbuffer())
            os.chdir('../')

            image_ids = os.listdir(upload_path)      # take name of all uploaded file
            if '.DS_Store' in image_ids:
                image_ids.remove('.DS_Store')
            # folder_len = len(image_ids)     # Take number of uploaded file

            # test_df = test_df[(test_df.index < folder_len)]     # remove images that could cause overflow
            test_df['image_id'] = image_ids     # add name of uploaded file to template
            paths = test_df.apply(lambda row: './upload/' + row['image_id'], axis=1)
            paths = paths.to_numpy()
            test_df['image_path'] = paths    # create filepaths



            # Prediction
            pred_cols = []

            for i, model_name in enumerate(glob.glob(models_dir + '/*.pth')):
                model = PaddyNet()
                model.load_state_dict(torch.load(model_name, map_location=torch.device('cpu')))     # load model
                model = model.to(params['device'])
                model.eval()        # evaluate model for uses
                
                X_test = test_df['image_path']      # read filepaths

                # create a dataset of images and apply augmentation to the images
                test_dataset = PaddyDataset(
                    images_filepaths=X_test.values,     
                    transform = get_test_transforms()
                )
                
                # data loader is used to load data
                test_loader = DataLoader(
                    test_dataset, batch_size=params['batch_size'],
                    shuffle=False, num_workers=params['num_workers'],
                    pin_memory=True
                )

                temp_preds = None
                with torch.no_grad():
                    for images in test_loader:
                        images = images.to(params['device'], non_blocking=True)
                        predictions = model(images).softmax(dim=1).argmax(dim=1).to('cpu').numpy()
                        
                        if temp_preds is None:
                            temp_preds = predictions
                        else:
                            temp_preds = np.hstack((temp_preds, predictions))

                test_df[f'model_{i}_preds'] = temp_preds
                pred_cols.append(f'model_{i}_preds')

            test_df['label'] = test_df[pred_cols].mode(axis=1)[0]
            test_df = test_df[['image_id', 'label']]
            label_col = test_df['label'].copy()
            test_df['label'] = test_df['label'].map(id2label)

            with res_col:
                st.write(test_df)
                for i in label_col.unique():
                        st.write(info["sol"][i])   

            with img_col:
                for img_path in os.listdir(upload_path)[:2]:
                    image = Image.open(os.path.join('./upload', img_path))
                    st.image(image, use_column_width='auto')

        except:
            pass

with tab2:
    st.write("""
    # RdpChat
    ChuyÃªn gia vá» bá»‡nh lÃºa
    """)
    st.write('[Giá»›i thiá»‡u:]')
    intro = [
        'RdpChat lÃ  má»™t AI chatbot Ä‘Æ°á»£c táº¡o ra Ä‘á»ƒ há»— trá»£ ngÆ°á»i nÃ´ng dÃ¢n vá» cÃ¡c kiáº¿n thá»©c vá» bá»‡nh lÃºa',
        'Chá»©c nÄƒng Ä‘ang trong gia Ä‘oáº¡n thá»­ nghiá»‡m',
        'Chá»‰ cÃ³ thá»ƒ tráº£ lá»i cÃ¡c cÃ¢u há»i liÃªn quan Ä‘áº¿n bá»‡nh lÃºa'
        ]
    st.write(intro)

    # session state
    if 'generated' not in st.session_state:
        st.session_state['generated'] = ["Xin chÃ o, tÃ´i lÃ  RDPchat, tÃ´i cÃ³ thá»ƒ giÃºp gÃ¬ cho báº¡n?"]
    if 'past' not in st.session_state:
        st.session_state['past'] = ['Xin chÃ o!']

    # input
    input_container = st.container()
    colored_header(label='', description='', color_name='blue-30')
    response_container = st.container()

    with input_container:
        user_input = get_text()

    with response_container:
        if user_input:
            response = generate_response(user_input)
            st.session_state.past.append(user_input)
            st.session_state.generated.append(response)
        
        if st.session_state['generated']:
            for i in range(len(st.session_state['generated'])):
                message(st.session_state['past'][i], is_user=True, key=str(i) + '_user')
                message(st.session_state['generated'][i], key=str(i))
    




